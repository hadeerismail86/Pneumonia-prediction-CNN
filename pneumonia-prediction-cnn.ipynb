{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**If you found it helpful, do upvote**\n\n**Feel free to comment**\n\n**I would love to have suggestions.**","metadata":{}},{"cell_type":"markdown","source":"# Import needed modules","metadata":{}},{"cell_type":"code","source":"# import system libs\nimport os\nimport time\nimport shutil\nimport pathlib\nimport itertools\nfrom PIL import Image\n\n# import data handling tools\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nsns.set_style('darkgrid')\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n# import Deep learning Libraries\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam, Adamax\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization\nfrom tensorflow.keras import regularizers\n\n# Ignore Warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nprint ('modules loaded')","metadata":{"execution":{"iopub.status.busy":"2023-08-20T17:31:04.072274Z","iopub.execute_input":"2023-08-20T17:31:04.073234Z","iopub.status.idle":"2023-08-20T17:31:14.688348Z","shell.execute_reply.started":"2023-08-20T17:31:04.073168Z","shell.execute_reply":"2023-08-20T17:31:14.687391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"**Read data and store it in dataframe**","metadata":{}},{"cell_type":"code","source":"train_data_dir = '/kaggle/input/labeled-chest-xray-images/chest_xray/train'\nfilepaths = []\nlabels = []\n\nfolds = os.listdir(train_data_dir)\nfor fold in folds:\n    foldpath = os.path.join(train_data_dir, fold)\n    filelist = os.listdir(foldpath)\n    for file in filelist:\n        fpath = os.path.join(foldpath, file)\n        \n        filepaths.append(fpath)\n        labels.append(fold)\n\n# Concatenate data paths with labels into one dataframe\nFseries = pd.Series(filepaths, name= 'filepaths')\nLseries = pd.Series(labels, name='labels')\ntrain_df = pd.concat([Fseries, Lseries], axis= 1)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T17:31:14.690365Z","iopub.execute_input":"2023-08-20T17:31:14.691344Z","iopub.status.idle":"2023-08-20T17:31:15.141440Z","shell.execute_reply.started":"2023-08-20T17:31:14.691301Z","shell.execute_reply":"2023-08-20T17:31:15.140507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df","metadata":{"execution":{"iopub.status.busy":"2023-08-20T17:31:15.142867Z","iopub.execute_input":"2023-08-20T17:31:15.143631Z","iopub.status.idle":"2023-08-20T17:31:15.162245Z","shell.execute_reply.started":"2023-08-20T17:31:15.143593Z","shell.execute_reply":"2023-08-20T17:31:15.161253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate data paths with labels\ntest_data_dir = '/kaggle/input/labeled-chest-xray-images/chest_xray/test'\nfilepaths = []\nlabels = []\n\nfolds = os.listdir(test_data_dir)\nfor fold in folds:\n    foldpath = os.path.join(test_data_dir, fold)\n    filelist = os.listdir(foldpath)\n    for file in filelist:\n        fpath = os.path.join(foldpath, file)\n        \n        filepaths.append(fpath)\n        labels.append(fold)\n\n# Concatenate data paths with labels into one dataframe\nFseries = pd.Series(filepaths, name= 'filepaths')\nLseries = pd.Series(labels, name='labels')\nts_df = pd.concat([Fseries, Lseries], axis= 1)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T17:31:15.164898Z","iopub.execute_input":"2023-08-20T17:31:15.165308Z","iopub.status.idle":"2023-08-20T17:31:15.355390Z","shell.execute_reply.started":"2023-08-20T17:31:15.165275Z","shell.execute_reply":"2023-08-20T17:31:15.354523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ts_df","metadata":{"execution":{"iopub.status.busy":"2023-08-20T17:31:15.357092Z","iopub.execute_input":"2023-08-20T17:31:15.358780Z","iopub.status.idle":"2023-08-20T17:31:15.369861Z","shell.execute_reply.started":"2023-08-20T17:31:15.358746Z","shell.execute_reply":"2023-08-20T17:31:15.368832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split data into train, valid, and test","metadata":{}},{"cell_type":"code","source":"# valid and test dataframe\nvalid_df, test_df = train_test_split(ts_df,  train_size= 0.5, shuffle= True, random_state= 123)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T17:31:15.371904Z","iopub.execute_input":"2023-08-20T17:31:15.372423Z","iopub.status.idle":"2023-08-20T17:31:15.380201Z","shell.execute_reply.started":"2023-08-20T17:31:15.372391Z","shell.execute_reply":"2023-08-20T17:31:15.379308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Create image data generator**","metadata":{}},{"cell_type":"code","source":"# crobed image size\nbatch_size = 64\nimg_size = (224, 224)\nchannels = 3\nimg_shape = (img_size[0], img_size[1], channels)\n\ntr_gen = ImageDataGenerator()\nts_gen = ImageDataGenerator()\n\ntrain_gen = tr_gen.flow_from_dataframe( train_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n                                    color_mode=\"rgb\", shuffle= True, batch_size= batch_size)\n\nvalid_gen = ts_gen.flow_from_dataframe( valid_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n                                        color_mode=\"rgb\", shuffle= True, batch_size= batch_size)\n\ntest_gen = ts_gen.flow_from_dataframe( test_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n                                    color_mode=\"rgb\", shuffle= False, batch_size= batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T17:31:15.381585Z","iopub.execute_input":"2023-08-20T17:31:15.382339Z","iopub.status.idle":"2023-08-20T17:31:24.042771Z","shell.execute_reply.started":"2023-08-20T17:31:15.382305Z","shell.execute_reply":"2023-08-20T17:31:24.041772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Show sample from train data**","metadata":{}},{"cell_type":"code","source":"g_dict = train_gen.class_indices      # defines dictionary {'class': index}\nclasses = list(g_dict.keys())       # defines list of dictionary's kays (classes), classes names : string\nimages, labels = next(train_gen)      # get a batch size samples from the generator\n\nplt.figure(figsize= (20, 20))\n\nfor i in range(16):\n    plt.subplot(4, 4, i + 1)\n    image = images[i] / 255       # scales data to range (0 - 255)\n    plt.imshow(image)\n    index = np.argmax(labels[i])  # get image index\n    class_name = classes[index]   # get class of image\n    plt.title(class_name, color= 'blue', fontsize= 12)\n    plt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-20T17:31:24.044135Z","iopub.execute_input":"2023-08-20T17:31:24.044604Z","iopub.status.idle":"2023-08-20T17:31:28.319908Z","shell.execute_reply.started":"2023-08-20T17:31:24.044561Z","shell.execute_reply":"2023-08-20T17:31:28.318711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Structure","metadata":{}},{"cell_type":"markdown","source":"**Generic Model Creation**","metadata":{}},{"cell_type":"code","source":"# Create Model Structure\nimg_size = (224, 224)\nchannels = 3\nimg_shape = (img_size[0], img_size[1], channels)\nclass_count = len(list(train_gen.class_indices.keys()))\n\nmodel = Sequential([\n    Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\", input_shape= img_shape),\n    Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n    MaxPooling2D((2, 2)),\n    \n    Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n    Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n    MaxPooling2D((2, 2)),\n    \n    Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n    Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n    Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n    MaxPooling2D((2, 2)),\n    \n    Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n    Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n    Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n    MaxPooling2D((2, 2)),\n    \n    Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n    Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n    Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n    MaxPooling2D((2, 2)),\n    \n    Flatten(),\n    Dense(256,activation = \"relu\"),\n    Dense(64,activation = \"relu\"),\n    Dense(class_count, activation = \"softmax\")\n])\n\nmodel.compile(Adamax(learning_rate= 0.001), loss= 'categorical_crossentropy', metrics= ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-08-20T17:31:28.321026Z","iopub.execute_input":"2023-08-20T17:31:28.321358Z","iopub.status.idle":"2023-08-20T17:31:31.546915Z","shell.execute_reply.started":"2023-08-20T17:31:28.321328Z","shell.execute_reply":"2023-08-20T17:31:31.545898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Train model**","metadata":{}},{"cell_type":"code","source":"epochs = 25   # number of all epochs in training\n\nhistory = model.fit(x= train_gen, epochs= epochs, verbose= 1, validation_data= valid_gen, \n                    validation_steps= None, shuffle= False)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T17:31:31.550688Z","iopub.execute_input":"2023-08-20T17:31:31.551223Z","iopub.status.idle":"2023-08-20T18:02:32.329230Z","shell.execute_reply.started":"2023-08-20T17:31:31.551181Z","shell.execute_reply":"2023-08-20T18:02:32.328242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Display model performance**","metadata":{}},{"cell_type":"code","source":"# Define needed variables\ntr_acc = history.history['accuracy']\ntr_loss = history.history['loss']\nval_acc = history.history['val_accuracy']\nval_loss = history.history['val_loss']\nindex_loss = np.argmin(val_loss)\nval_lowest = val_loss[index_loss]\nindex_acc = np.argmax(val_acc)\nacc_highest = val_acc[index_acc]\nEpochs = [i+1 for i in range(len(tr_acc))]\nloss_label = f'best epoch= {str(index_loss + 1)}'\nacc_label = f'best epoch= {str(index_acc + 1)}'\n\n# Plot training history\nplt.figure(figsize= (20, 8))\nplt.style.use('fivethirtyeight')\nplt.subplot(1, 2, 1)\nplt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\nplt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\nplt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\nplt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\nplt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.subplot(1, 2, 2)\nplt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\nplt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\nplt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.tight_layout\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-20T18:02:32.332814Z","iopub.execute_input":"2023-08-20T18:02:32.333113Z","iopub.status.idle":"2023-08-20T18:02:33.144547Z","shell.execute_reply.started":"2023-08-20T18:02:32.333086Z","shell.execute_reply":"2023-08-20T18:02:33.143643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate model","metadata":{}},{"cell_type":"code","source":"ts_length = len(test_df)\ntest_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\ntest_steps = ts_length // test_batch_size\n\ntrain_score = model.evaluate(train_gen, steps= test_steps, verbose= 1)\nvalid_score = model.evaluate(valid_gen, steps= test_steps, verbose= 1)\ntest_score = model.evaluate(test_gen, steps= test_steps, verbose= 1)\n\nprint(\"Train Loss: \", train_score[0])\nprint(\"Train Accuracy: \", train_score[1])\nprint('-' * 20)\nprint(\"Valid Loss: \", valid_score[0])\nprint(\"Valid Accuracy: \", valid_score[1])\nprint('-' * 20)\nprint(\"Test Loss: \", test_score[0])\nprint(\"Test Accuracy: \", test_score[1])","metadata":{"execution":{"iopub.status.busy":"2023-08-20T18:02:33.146096Z","iopub.execute_input":"2023-08-20T18:02:33.146681Z","iopub.status.idle":"2023-08-20T18:02:48.462737Z","shell.execute_reply.started":"2023-08-20T18:02:33.146645Z","shell.execute_reply":"2023-08-20T18:02:48.461151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Get Predictions**","metadata":{}},{"cell_type":"code","source":"preds = model.predict_generator(test_gen)\ny_pred = np.argmax(preds, axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T18:02:48.464100Z","iopub.execute_input":"2023-08-20T18:02:48.464823Z","iopub.status.idle":"2023-08-20T18:02:52.537419Z","shell.execute_reply.started":"2023-08-20T18:02:48.464787Z","shell.execute_reply":"2023-08-20T18:02:52.536360Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Confusion Matrics and Classification Report**","metadata":{}},{"cell_type":"code","source":"g_dict = test_gen.class_indices\nclasses = list(g_dict.keys())\n\n# Confusion matrix\ncm = confusion_matrix(test_gen.classes, y_pred)\n\nplt.figure(figsize= (10, 10))\nplt.imshow(cm, interpolation= 'nearest', cmap= plt.cm.Blues)\nplt.title('Confusion Matrix')\nplt.colorbar()\n\ntick_marks = np.arange(len(classes))\nplt.xticks(tick_marks, classes, rotation= 45)\nplt.yticks(tick_marks, classes)\n\ntick_marks = np.arange(len(classes))\nplt.xticks(tick_marks, classes, rotation= 45)\nplt.yticks(tick_marks, classes)\n\n\nthresh = cm.max() / 2.\nfor i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    plt.text(j, i, cm[i, j], horizontalalignment= 'center', color= 'white' if cm[i, j] > thresh else 'black')\n\nplt.tight_layout()\nplt.ylabel('True Label')\nplt.xlabel('Predicted Label')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-20T18:02:52.538838Z","iopub.execute_input":"2023-08-20T18:02:52.539214Z","iopub.status.idle":"2023-08-20T18:02:52.963398Z","shell.execute_reply.started":"2023-08-20T18:02:52.539157Z","shell.execute_reply":"2023-08-20T18:02:52.962473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Classification report\nprint(classification_report(test_gen.classes, y_pred, target_names= classes))","metadata":{"execution":{"iopub.status.busy":"2023-08-20T18:02:52.964792Z","iopub.execute_input":"2023-08-20T18:02:52.965234Z","iopub.status.idle":"2023-08-20T18:02:52.980080Z","shell.execute_reply.started":"2023-08-20T18:02:52.965184Z","shell.execute_reply":"2023-08-20T18:02:52.979203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Save model**","metadata":{}},{"cell_type":"code","source":"#Save the model\nmodel.save('Model.h5')","metadata":{"execution":{"iopub.status.busy":"2023-08-20T18:02:52.981333Z","iopub.execute_input":"2023-08-20T18:02:52.981729Z","iopub.status.idle":"2023-08-20T18:02:53.423012Z","shell.execute_reply.started":"2023-08-20T18:02:52.981697Z","shell.execute_reply":"2023-08-20T18:02:53.422010Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Prediction using loaded_model**","metadata":{}},{"cell_type":"code","source":"loaded_model = tf.keras.models.load_model('/kaggle/working/Model.h5', compile=False)\nloaded_model.compile(Adamax(learning_rate= 0.001), loss= 'categorical_crossentropy', metrics= ['accuracy'])\n\nimage_path = '/kaggle/input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets/lung_aca/lungaca1001.jpeg'\nimage = Image.open(image_path)\n\n# Preprocess the image\nimg = image.resize((224, 224))\nimg_array = tf.keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0)\n#img_data=preprocess_input(img-array)\n\n# Make predictions\npredictions = loaded_model.predict(img_array)\nclass_labels = classes\nscore = tf.nn.softmax(predictions[0])\nprint(f\"{class_labels[tf.argmax(score)]}\")","metadata":{"execution":{"iopub.status.busy":"2023-08-20T18:02:53.424338Z","iopub.execute_input":"2023-08-20T18:02:53.424686Z","iopub.status.idle":"2023-08-20T18:02:54.732570Z","shell.execute_reply.started":"2023-08-20T18:02:53.424648Z","shell.execute_reply":"2023-08-20T18:02:54.731015Z"},"trusted":true},"execution_count":null,"outputs":[]}]}